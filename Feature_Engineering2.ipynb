{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8435b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers \n",
    "\n",
    "datapath = \"./dataset/\"\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, train_ids, test_ids = helpers.load_csv_data(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac313336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 321)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./dataset/x_train.csv\"\n",
    "feature_names =  np.genfromtxt(data_path, max_rows=2, delimiter=',', names=True).dtype.names\n",
    "feature_names = feature_names[1:] ## TODO , j'ai l'impression qu'il faut faire ça vue que x_train a pas ID\n",
    "columns = np.asarray(feature_names[0:])\n",
    "columns\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9c16e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  \\n   on peux remplacer \\n\\n for i in range(len(new_column)):\\n       if new_column[i] == 3:  \\n            new_column[i] = 0\\n\\n    par ça , c'est plus court et aussi lisible \\n    new_column[new_column==3]=0\\n \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO ATTENTION , dans chaque process ,     new_column = column.copy() \n",
    "# Python fait du passage par référence \n",
    " \n",
    "\n",
    "# TODO , all the variable in variables_for_process2 could be encode using one_hot_encoding_special,2,[7,9]\n",
    "\n",
    "# \n",
    "\"\"\"\n",
    "  \n",
    "   on peux remplacer \n",
    "\n",
    " for i in range(len(new_column)):\n",
    "       if new_column[i] == 3:  \n",
    "            new_column[i] = 0\n",
    "\n",
    "    par ça , c'est plus court et aussi lisible \n",
    "    new_column[new_column==3]=0\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2527deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "collumns_to_delete = []\n",
    "D = x_train.shape[1]\n",
    "\n",
    "for i in range(D-1):\n",
    "    if len(np.where(np.isnan(x_train[:,i]))[0]) > x_train.shape[0]*0.60: #TODO Deleting collumns with >95% nan \n",
    "        collumns_to_delete.append(columns[i])\n",
    "\n",
    "\n",
    "\n",
    "len(collumns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d4ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot encode special shape  61\n",
      "hot encode normal  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9_/z1m27wy57j34pk1k36dtbd280000gn/T/ipykernel_16504/3381973917.py:78: RuntimeWarning: invalid value encountered in cast\n",
      "  int_coll = collumn.astype(int)\n",
      "/var/folders/9_/z1m27wy57j34pk1k36dtbd280000gn/T/ipykernel_16504/3381973917.py:89: RuntimeWarning: invalid value encountered in cast\n",
      "  collumn_as_int = collumn.astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((328135, 415), (109379, 415))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Acess to collumns i : x_train[:,i]\n",
    "x_new_train = np.copy(x_train) \n",
    "x_append_train = np.empty((x_train.shape[0],0))\n",
    "\n",
    "x_new_test= np.copy(x_test) \n",
    "x_append_test = np.empty((x_test.shape[0],0))\n",
    "\n",
    "def standardize(x):\n",
    "    \"\"\"Standardize the original data set.\"\"\"\n",
    "    mean_x = np.mean(x)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x)\n",
    "    x = x / std_x\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing_refactorisation(list_of_collumns_to_process,processing_function):\n",
    "    for col in list_of_collumns_to_process:\n",
    "        tab = [i for i, item in enumerate(feature_names) if item.find(col) != -1 ]\n",
    "        if (len(tab)>0):\n",
    "            indice = tab[0]\n",
    "            x_new_train[:,indice] = standardize(processing_function(x_train[:,indice]))\n",
    "            x_new_test[:,indice] = standardize(processing_function(x_test[:,indice]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO CAREFULL , ONE hot Encoding increase the size of the size of the dataset\n",
    "\n",
    "collumn_to_oneHotEncode = [\"_STATE\",\"IMONTH\",\"IDAY\",\"SEX\",\"_DRDXAR1\",\"_RACE_G1\",\"_BMI5CAT\",\"ACTIN11_\",\"ACTIN21_\"]\n",
    "collumn_to_oneHotencode_special = [(\"MARITAL\",6,[9]),(\"EDUCA\",6,[9]),(\"RENTHOM1\",3,[7,9]),(\"EMPLOY1\",8,[9]),(\"INCOME2\",8,[77,99]),(\"GENHLTH\",5,[7,9]),\n",
    "                                   (\"HAREHAB1\",2,[7,9]),(\"STREHAB1\",2,[7,9]),(\"CVDASPRN\",2,[7,9]),(\"ASPUNSAF\",3,[7,9]),(\"RLIVPAIN\",2,[7,9]),(\"RDUCHART\",2,[7,9]),\n",
    "                                   (\"RDUCSTRK\",2,[7,9]),(\"ARTHWGT\",2,[7,9]),(\"ARTHEXER\",2,[7,9]),(\"ARTHEDU\",2,[7,9]),\n",
    "                                   (\"TETANUS\",4,[7,9]),(\"HPVADVC2\",3,[7,9]),(\"HPVADSHT\",3,[77,99]),(\"SHINGLE2\",2,[7,9]),\n",
    "                                   (\"SCNTLPAD\",4,[7,9]),(\"SXORIENT\",4,[7,9]),(\"TRNSGNDR\",4,[7,9]),\n",
    "                                   (\"CASTHDX2\",2,[7,9]),(\"CASTHNO2\",2,[7,9]),(\"MISTMNT\",2,[7,9]),(\"ADANXEV\",2,[7,9]),(\"_CRACE1\",7,[77,99]),\n",
    "                                   (\"_CPRACE\",7,[77,99]),\n",
    "                                   (\"_RFHLTH\",2,[9]),(\"_HCVU651\",2,[9]),(\"_RFHYPE5\",2,[9]),(\"_CHOLCHK\",3,9),(\"_RFCHOL\",2,[9]),(\"_LTASTH1\",2,9),(\"_CASTHM1\",2,[9]),\n",
    "                                    (\"_ASTHMS1\",3,[9]),(\"_PRACE1\",8,[77,99]),(\"_MRACE1\",7,[77,99]),(\"_HISPANC\",2,[9]),(\"_RACE\",8,[9]),(\"_RACEG21\",2,[9]),\n",
    "                                    (\"_RACEGR3\",5,[9]),(\"_AGEG5YR\",13,[14]),(\"_AGE65YR\",2,[3]),(\"_RFBMI5\",2,[9]),(\"_CHLDCNT\",6,[9]),(\"_RFSMOK3\",2,[9]),\n",
    "                                    (\"DRNKANY5\",2,[7,9]),(\"_RFBING5\",2,[9]),(\"_RFDRHV5\",2,[9]),(\"_FRTLT1\",2,[9]),(\"_VEGLT1\",2,[9]),(\"_TOTINDA\",2,[9]),\n",
    "                                    (\"_PAINDX1\",2,[9]),(\"_PAREC1\",4,[9])\n",
    "                                   ]\n",
    "\n",
    "\n",
    "collumn_to_oneHotencode_special_123 = [(\"PERSDOC2\",3,[7,9]),(\"SMOKDAY2\",3,[7,9])]\n",
    "collumn_to_oneHotencode_special_pregnancy = [(\"BPHIGH4\",4,[7,9]),(\"DIABETE3\",4,[7,9]),(\"PREDIAB1\",3,[7,9])]\n",
    "\n",
    "\n",
    "collumn_to_oneHotencode_special= collumn_to_oneHotencode_special+collumn_to_oneHotencode_special_123+collumn_to_oneHotencode_special_pregnancy\n",
    "\n",
    "\n",
    "print(\"hot encode special shape \",len(collumn_to_oneHotencode_special))\n",
    "print(\"hot encode normal \",len(collumn_to_oneHotEncode))\n",
    "\n",
    "#One hot encoded collumns must be deleted\n",
    "collumns_to_delete_from_one_hot =[\"_STATE\",\"IMONTH\",\"IDAY\",\n",
    "                                  \"SEX\",\"MARITAL\",\"EDUCA\",\"RENTHOM1\",\"EMPLOY1\",\"INCOME2\",\"GENHLTH\",\n",
    "                                  \"PERSDOC2\",\"SMOKDAY2\",\n",
    "                                  \"BPHIGH4\",\"DIABETE3\",\"PREDIAB1\",\n",
    "                                  \"HAREHAB1\",\"STREHAB1\",\"CVDASPRN\",\"ASPUNSAF\",\"RLIVPAIN\",\"RDUCHART\",\"RDUCSTRK\",\"ARTHWGT\",\"ARTHEXER\",\"ARTHEDU\",\n",
    "                                  \"TETANUS\",\"HPVADVC2\",\"HPVADSHT\",\"SHINGLE2\",\"SCNTLPAD\",\"SXORIENT\",\"TRNSGNDR\",\"CASTHDX2\",\"CASTHNO2\",\"MISTMNT\",\n",
    "                                  \"ADANXEV\",\"_CRACE1\",\"_CPRACE\",\"_RFHLTH\",\"_HCVU651\",\"_RFHYPE5\",\"_CHOLCHK\",\"_RFCHOL\",\"_MICHD\",\"_LTASTH1\",\"_CASTHM1\",\n",
    "                                  \"_ASTHMS1\",\"_DRDXAR1\",\"_PRACE1\",\"_MRACE1\",\"_HISPANC\",\"_RACE\",\"_RACEG21\",\"_RACEGR3\",\"_RACE_G1\",\n",
    "                                  \"_AGEG5YR\",\"_AGE65YR\",\"_BMI5CAT\",\"_RFBMI5\",\"_CHLDCNT\",\"_RFSMOK3\",\"DRNKANY5\",\"_RFBING5\",\"_RFDRHV5\",\"_FRTLT1\",\"_VEGLT1\",\"_TOTINDA\",\"ACTIN11_\",\"ACTIN21_\",\n",
    "                                  \"_PAINDX1\",\"_PAREC1\",\n",
    "                                  ]\n",
    "\n",
    "\n",
    "collumns_to_delete = collumns_to_delete+collumns_to_delete_from_one_hot\n",
    "\n",
    "\n",
    "\n",
    "#One hot encoding of the collumn , Assumes that the collumn contains value between 1 and K\n",
    "def one_hot_encoding(collumn):\n",
    "    int_coll = collumn.astype(int)\n",
    "    num_classes = max(int_coll)+1\n",
    "    result = np.eye(num_classes)[int_coll]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# ONe hot encoding of the collumn , assumes that the collumns contains values between 1 and num_max , and that the value skip correspond to Nan / not answered ...\n",
    "\n",
    "def one_hot_encoding_special(collumn,num_max,skip):\n",
    "\n",
    "    collumn_as_int = collumn.astype(int)\n",
    "    num_classes = num_max+1\n",
    "    collumn_as_int[np.isin(collumn_as_int, skip)]=0\n",
    "    result = np.eye(num_classes)[collumn_as_int]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "for col in collumn_to_oneHotEncode :\n",
    "    indice = [i for i, item in enumerate(feature_names) if item.find(col) != -1][0]\n",
    "    encoded_train  = one_hot_encoding(x_train[:,indice])\n",
    "    x_append_train = np.hstack((x_append_train,encoded_train))\n",
    "\n",
    "    encoded_test = one_hot_encoding(x_test[:,indice])\n",
    "    x_append_test = np.hstack((x_append_test,encoded_test))\n",
    "\n",
    "    \n",
    "\n",
    "for col,num_max,skip in collumn_to_oneHotencode_special:\n",
    "    indice = [i for i, item in enumerate(feature_names) if item.find(col) != -1][0]\n",
    "    encoded_train  = one_hot_encoding_special(x_train[:,indice],num_max,skip)\n",
    "    x_append_train = np.hstack((x_append_train,encoded_train))\n",
    "\n",
    "    encoded_test  = one_hot_encoding_special(x_test[:,indice],num_max,skip)\n",
    "    x_append_test = np.hstack((x_append_test,encoded_test))\n",
    "\n",
    "\n",
    "x_append_train.shape,x_append_test.shape # Currently , shape 415"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184ce56",
   "metadata": {},
   "source": [
    "I think we should not consider IDATE, we should directly consider IMONTH, IDAY, IYEAR since it corresponds to the same thing, we should consider the columns to potentially drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f015ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "array_to_trop_list = [\"DIS\"]\n",
    "array_to_drop_Useless = [\"_PSU\",\"SEQNO\",\"CTELENUM\",\"STATERES\",\"CELLFON3\",\"DISPCODE\",\"PVTRESD1\",\"CTELNUM1\",\"CELLFON2\",\n",
    "                         \"PVTRESD2\",\"LANDLINE\",\"HHADULT\",\"NUMHHOL2\",\"IMFVPLAC\",\"WHRTST10\",\"NUMADULT\" , \"NUMMEN\" , \"NUMWOMEN\",\n",
    "                         \"RCSGENDR\",\"RCSRLTN2\",\"QSTVER\",\"QSTLANG\",\"EXACTOT1\",\"EXACTOT2\",\"MSCODE\",\"_STSTR\",\"_STRWT\",\"_RAWRAKE\",\"_WT2RAKE\",\n",
    "                         \"_CHISPNC\",\"_CLLCPWT\",\"_DUALUSE\",\"_DUALCOR\",\n",
    "                         \"_AGE_G\",\"HTIN4\",\"WTKG3\",\"HTM4\",\n",
    "                         \n",
    "                         \n",
    "\n",
    "                         \"_MISFRTN\",\"_MISVEGN\",\"_FRTRESP\",\"_VEGRESP\",\"_FRT16\",\"_VEG23\",\"_FRUITEX\",\"_VEGETEX\",\n",
    "                         \"PAMISS1_\",\"_LMTSCL1\",\"_RFSEAT2\",\"_RFSEAT3\",\"_FLSHOT6\",\"_PNEUMO2\",\"_AIDTST3\"\n",
    "\n",
    "                         ,\"CHOLCHK\",\"FLSHTMY2\",\"FEETCHK2\",\"FEETCHK\",\n",
    "                         \"LONGWTCH\" #maybe use it later \n",
    "                         \n",
    "                         \n",
    "                         ]\n",
    "array_to_drop_redundant = [\"IDATE\",\"FMONTH\",\"IYEAR\"] #IYEAR is useless , 99% in 2015\n",
    "array_to_drop_too_many_missing =[\"LADULT\",\"COLGHOUS\",\"CADULT\",\"CCLGHOUS\",\"CSTATE\",\"NUMPHON2\", \"PAINACT2\",\"QLMENTL2\",\"QLSTRES2\",\"QLHLTH2\",\n",
    "                                 \"CRGVREL1\",\"CRGVLNG1\",\"CRGVHRS1\",\"CRGVPRB1\",\"CRGVPERS\", \"CRGVHOUS\",\"CRGVMST2\",\"CRGVEXPT\",\"HIVTSTD3\",\"VIDFCLT2\",\n",
    "                                 \"VIREDIF3\",\"VIPRFVS2\",\"VINOCRE2\",\"VIEYEXM2\",\"VIINSUR2\",\"VICTRCT4\",\"ASERVIST\",\"ASDRVIST\",\"ASRCHKUP\",\"ASACTLIM\",\"ASYMPTOM\",\"ASNOSLEP\",\n",
    "                                 \"ASTHMED3\",\"ASINHALR\"\n",
    "                                 \"PCPSADE1\",\"PCDMDECN\"\n",
    "                                 ]\n",
    "array_to_drop_or_to_oneHot =[\"EXRACT11\",\"EXRACT21\"]\n",
    "\n",
    "collumns_to_delete = collumns_to_delete + array_to_trop_list+array_to_drop_Useless+array_to_drop_redundant+array_to_drop_too_many_missing+array_to_drop_or_to_oneHot\n",
    "\n",
    "len(collumns_to_delete)\n",
    "\n",
    "#CAREFULL , DO NOT RUN MULTIPLE TIME , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f31798",
   "metadata": {},
   "source": [
    "Process for PHYSHLTH, MENTHLTH, POORHLTH \n",
    "The values corresponds to days, between 1-30 it is already good.\n",
    "We're going to replace all 88 values by 0 because it corresponds to None which is 0 days, and we will assume that those who refused or did not answer have median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89372a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_HLTH(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 88: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 30]        \n",
    "    median = np.nanmedian(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77) or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8223a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process_HLTH = [\"PHYSHLTH\",\"MENTHLTH\", \"POORHLTH\"]\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process_HLTH,process_HLTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e0766",
   "metadata": {},
   "source": [
    "Process for values that have as answer Yes or No\n",
    "We're going to replace No by 0 and yes by 1, since yes is already by 1, we're going to change 2 by 0. For values 7 which corresponds to don't know or not sure, 9 for refused, and BLANK for missing values, we're going to take the median\n",
    "\n",
    "We're going to use this method for variables : HLTHPLN1, MEDCOST, BPMEDS, BLOODCHO, TOLDHI2, CVDINFR4, CVDCRHD4, CVDSTRK3, ASTHMA3, ASTHNOW, CHCSCNCR, CHCOCNCR, CHCCOPD1, HAVARTH3, ADDEPEV2, CHCKIDNY, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e8b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_2(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 2: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 1]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7) or (new_column[i] == 9) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e1db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process2 = [\"HLTHPLN1\", \"MEDCOST\", \"BPMEDS\", \"BLOODCHO\", \"TOLDHI2\",\n",
    "                          \"CVDSTRK3\", \"ASTHMA3\", \"ASTHNOW\",\n",
    "                          \"CHCSCNCR\", \"CHCOCNCR\", \"CHCCOPD1\", \"HAVARTH3\", \"ADDEPEV2\",\n",
    "                          \"CHCKIDNY\", \"CPDEMO1\", \"VETERAN3\", \"INTERNET\", \"PREGNANT\",\n",
    "                         \"QLACTLM2\", \"USEEQUIP\", \"BLIND\", \"DECIDE\", \"DIFFWALK\", \"DIFFDRES\",\n",
    "                          \"DIFFALON\", \"SMOKE100\",\"STOPSMK2\", \"EXERANY2\",\n",
    "                         \"LMTJOIN3\", \"ARTHDIS2\", \"FLUSHOT6\", \"PNEUVAC3\",\n",
    "                         \"HIVTST6\", \"PDIABTST\", \"INSULIN\", \"DIABEYE\", \"DIABEDU\",\"CAREGIV1\",\"VIGLUMA2\",\"VIMACDG2\",\"CIMEMLOS\",\"CDDISCUS\",\n",
    "                         \"WTCHSALT\",\"DRADVISE\",\"ASATTACK\",\n",
    "                         \"HADMAM\",\"HADPAP2\",\"HPVTEST\",\"HADHYST2\",\"PROFEXAM\",\"BLDSTOOL\",\n",
    "                         \"HADSIGM3\",\"HADSGCO1\",\"PCPSAAD2\",\"PCPSADI1\",\"PCPSARE1\",\"PSATEST1\",\n",
    "                         \"_PA30021\",\"_PASTRNG\",\"_PASTAE1\"\n",
    "                         ]\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process2,process_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db4ebd",
   "metadata": {},
   "source": [
    "Process for CHECKUP1, we have to check what to do with never have been checked I gave 0 but I think we should instead do 5\n",
    "see how we can do both CHOLCHK and CHECKUP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e9b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_3(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 8: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 4]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7) or (new_column[i] == 9) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8963f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process3 = [\"CHECKUP1\"]\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process3,process_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c96591",
   "metadata": {},
   "source": [
    "See process for DIABAGE2, how old were you (ages between 1-97) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c83622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_4(column):\n",
    "    new_column = column.copy()\n",
    "\n",
    "    filtered_elements = [x for x in new_column if 1 <= x <= 97]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 98) or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "077f5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO DIABAGE2 has 384 204 missing values , do we keep it ? \n",
    "\n",
    "variables_for_process4 = [\"DIABAGE2\"]\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process4,process_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183fd73",
   "metadata": {},
   "source": [
    "See process for CHILDREN, values between 1-87, None corresponds to 88 we will transform to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c164ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_5(column):\n",
    "    new_column = column\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 88: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 87]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 98) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c624ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process5 = [\"CHILDREN\"]\n",
    "\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process5,process_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941d900",
   "metadata": {},
   "source": [
    "See process for WEIGHT2, For weight we will put everything in kilograms, so for values between 50-0999 which is in pound we will transform it it kg, and for values between 9000-9998 we will remove the first column of the value because it only corresponds to the fact that the value is in kg.\n",
    "\n",
    "See process for HEIGHT3, we will transform everything in centimeters, from inches to centimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b028073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_6_weight(column):\n",
    "    new_column = column.copy()\n",
    "\n",
    "    \n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] >= 50 and new_column[i] <= 999: \n",
    "            new_column[i] = new_column[i] * 0.453592\n",
    "        elif new_column[i] >= 9000 and new_column[i] <= 9998: \n",
    "            new_column[i] = new_column[i] - 9000\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 999]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7777) or (new_column[i] == 9999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column\n",
    "\n",
    "def process_6_height(column):\n",
    "    new_column = column.copy()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] >= 200 and new_column[i] <= 711: \n",
    "\n",
    "            feet = new_column[i]//100\n",
    "            inch = (new_column[i]-feet*100)+feet*12\n",
    "            new_column[i] = inch* 2.54\n",
    "        elif new_column[i] >= 9000 and new_column[i] <= 9998: \n",
    "            new_column[i] = new_column[i] - 9000\n",
    "\n",
    "       \n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 999]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7777) or (new_column[i] == 9999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09a62ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_refactorisation([\"WEIGHT2\"],process_6_weight)\n",
    "preprocessing_refactorisation([\"HEIGHT3\"],process_6_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6f2ea",
   "metadata": {},
   "source": [
    "We do process for ALCDAY5 where :\n",
    "- the value in the form 1_ _ = days per week, there are 4 week per month\n",
    "- 2_ _ = days in the past 30 day\n",
    "- 888 no drinks we will then consider 0\n",
    "- for the values 777, 999, BLANK, we will consider the mean\n",
    "\n",
    "The new value corresponds to the number of days per month you consumed at least one drink\n",
    "\n",
    "Same thing works for EXEROFT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "902018d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_7(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] >= 101 and new_column[i] <= 199: \n",
    "            new_column[i] = (new_column[i] - 100) * 4\n",
    "        elif new_column[i] >= 201 and new_column[i] <= 299: \n",
    "            new_column[i] = (new_column[i] - 200)\n",
    "        elif (new_column[i] == 888): \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 99]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 777) or (new_column[i] == 999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc33ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process7 = [\"ALCDAY5\", \"EXEROFT1\", \"EXEROFT2\", \"STRENGTH\"]\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process7,process_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e97fe",
   "metadata": {},
   "source": [
    "Do process for Alcohol, especially for AVEDRNK2 and the other, we are considering if it is BLANK because it is not asked since the previous answer is no (888), which is the answer to the question have you had any alcoholic beverage. Since the answer to the variable name ALCDAY5 is no they will not ask the other questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "095a0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_8(column, column_ALCDAY5):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if (np.isnan(new_column[i]) and column_ALCDAY5[i] == 888): \n",
    "            new_column[i] = 0\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 76]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77) or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4cf6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "variables_for_process8 = [\"AVEDRNK2\", \"DRNK3GE5\", \"MAXDRNKS\" ]\n",
    "indice_ALCDAY5 = [i for i, item in enumerate(feature_names) if item.find(\"ALCDAY5\") != -1 ][0]\n",
    "for col in variables_for_process8 :\n",
    "    indice = [i for i, item in enumerate(feature_names) if item.find(col) != -1 ][0]\n",
    "    x_new_train[:,indice] = process_8(x_train[:,indice], x_train[:,indice_ALCDAY5])\n",
    "    x_new_test[:,indice] = process_8(x_test[:,indice], x_test[:,indice_ALCDAY5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ac6e9",
   "metadata": {},
   "source": [
    "Process for FRUITJU1, FRUIT1, FVBEANS, FVGREEN, FVORANG, VEGETAB1  . We are going to use  information about FRUITJUI1 to understand how the values in FRUIT1 works, indeed,\n",
    "- the value in the form 1_ _ = times per day, we will consider there are 30 days per month\n",
    "- 2_ _ = times per week, we will consider there are 4 weeks per month (maybe you want to consider more 4,..)\n",
    "- 300 means less than one time per month, we will consider 0 \n",
    "- 3_ _ = times per month\n",
    "- 555 never we will then consider 0\n",
    "- for the values 777, 999, BLANK we will consider the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8f50736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_9(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] >= 101 and new_column[i] <= 199: \n",
    "            new_column[i] = (new_column[i] - 100) * 30\n",
    "        elif new_column[i] >= 201 and new_column[i] <= 299: \n",
    "            new_column[i] = (new_column[i] - 200) * 4\n",
    "        elif (new_column[i] == 300) or (new_column[i] == 555): \n",
    "            new_column[i] = 0\n",
    "        elif new_column[i] >= 301 and new_column[i] <= 399: \n",
    "            new_column[i] = (new_column[i] - 300)\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 99]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 777) or (new_column[i] == 999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "866ef97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "variables_for_process9 = [\"FRUITJU1\", \"FRUIT1\", \"FVBEANS\",\n",
    "                          \"FVGREEN\", \"FVORANG\", \"VEGETAB1\"]\n",
    "preprocessing_refactorisation(variables_for_process9,process_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4eb136",
   "metadata": {},
   "source": [
    "We do process for EXERHMM1, we have values in hours and minutes, we want it to be continious, we have _ _ _, the first value correspond to the number of hours, the two other values correspond to minutes, We will convert everything to minutes \n",
    "Also works for EXERHMM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "551542da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_10(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] >= 1 and new_column[i] <= 759) \n",
    "        or (new_column[i] >= 800 and new_column[i] <= 959)):             \n",
    "            first_digit = new_column[i] // 100\n",
    "            digits2_3 = new_column[i] % 100           \n",
    "            new_column[i] = first_digit * 60 + digits2_3\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 600]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 777) or (new_column[i] == 999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dad8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process10 = [\"EXERHMM1\", \"EXERHMM2\"]\n",
    "\n",
    "preprocessing_refactorisation(variables_for_process10,process_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01400e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2546e16",
   "metadata": {},
   "source": [
    "DO IMFVPLAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf7b417",
   "metadata": {},
   "source": [
    "We will process the values for BLDSUGAR, FEETCHK2\n",
    "We want to have the times they checked something per year:\n",
    "- the value in the form 1_ _ = times per day, we will consider there are 365 days in a year\n",
    "- 2_ _ = times per week, we will consider there are 52 weeks per year (you may want to consider there are more (52,143))\n",
    "- 3_ _ = times per month, we consider there are 12 months in a year\n",
    "- 4_ _ = times per year\n",
    "- 555 no feet, we will then consider 0\n",
    "- 888 never, whichi means 0\n",
    "- for the values 777, 999, BLANK we will consider the median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b01b6c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_11(column):\n",
    "    \n",
    "    new_column = column.copy()\n",
    "    \n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] >= 101 and new_column[i] <= 199: \n",
    "            new_column[i] = (new_column[i] - 100) * 365\n",
    "        elif new_column[i] >= 201 and new_column[i] <= 299: \n",
    "            new_column[i] = (new_column[i] - 200) * 52\n",
    "        elif new_column[i] >= 301 and new_column[i] <= 399: \n",
    "            new_column[i] = (new_column[i] - 300) * 12\n",
    "        elif new_column[i] >= 401 and new_column[i] <= 499: \n",
    "            new_column[i] = new_column[i] - 400\n",
    "        elif (new_column[i] == 300) or (new_column[i] == 555): \n",
    "            new_column[i] = 0\n",
    "\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 99]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 777) or (new_column[i] == 999) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46cb96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process11 = [\"BLDSUGAR\", \"FEETCHK2\"]\n",
    "preprocessing_refactorisation(variables_for_process11,process_11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f6483",
   "metadata": {},
   "source": [
    "Process for DOCTDIAB, CHKHEMO3, FEETCHK\n",
    "We want all the values to be between 0-76 that corresponds to how many times they did something\n",
    "- 88 which corresponds to None/ 0\n",
    "- 98 never heard of means they have done it 0 times\n",
    "- for the values 77-99-BLANK we will again consider the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84001855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_12(column):\n",
    "    new_column = column.copy()\n",
    "    for i in range(len(new_column)):\n",
    "        if (new_column[i] == 88 or new_column[i] == 98 ): \n",
    "            new_column[i] = 0\n",
    "\n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 76]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77) or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "380eb674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoineschutz/Library/Python/3.9/lib/python/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/antoineschutz/Library/Python/3.9/lib/python/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "variables_for_process12 = [\"DOCTDIAB\",\"CHKHEMO3\",\"FEETCHK\"]\n",
    "preprocessing_refactorisation(variables_for_process12,process_12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da44ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_13(column):\n",
    "    new_column = column.copy()\n",
    "    # Never is mapped to 0 , some days mapped to 1 and every day mapped to 2 \n",
    "    new_column[new_column==3]=0\n",
    "    new_column[new_column==2]=1\n",
    "    new_column[new_column==1]=2\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 2]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7) or (new_column[i] == 9) or np.isnan(new_column[i])): # DON'T KNOW / REFUSED \n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f281991",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process13 = [\"USENOW3\",\"ARTHSOCL\",\"SMOKDAY2\",\"_PA150R2\",\"_PA300R2\",\"_LMTACT1\",\"_LMTWRK1\"]\n",
    "preprocessing_refactorisation(variables_for_process13,process_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b064a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_14(column):\n",
    "    new_column = column.copy()\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 10]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77) or (new_column[i] == 99) or np.isnan(new_column[i])): # DON'T KNOW / REFUSED \n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95486955",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process14 = [\"JOINPAIN\"]\n",
    "preprocessing_refactorisation(variables_for_process14,process_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "694ae9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_15(column):\n",
    "    new_column = column.copy()\n",
    "    new_column[new_column==8]=5\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 5]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7) or (new_column[i] == 9) or np.isnan(new_column[i])): # DON'T KNOW / REFUSED \n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3716272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process15 = [\"EYEEXAM\",\"ARTTODAY\",\"SCNTMNY1\",\"SCNTMEL1\",\"SCNTPAID\",\"_EDUCAG\",\"_INCOMG\",\"_SMOKER3\",\"_PACAT1\"]\n",
    "preprocessing_refactorisation(variables_for_process15,process_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "befbea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_16(column):\n",
    "    new_column = column.copy()\n",
    "\n",
    "    new_column[new_column==8]=1\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 6]\n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 7) or (new_column[i] == 9) or np.isnan(new_column[i])): # DON'T KNOW / REFUSED \n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b40240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process16 = [\"SEATBELT\",\"CDHOUSE\",\"CDASSIST\",\"CDHELP\",\"CDSOCIAL\",\"HOWLONG\",\n",
    "                           \"LASTPAP2\",\"HPLSTTST\",\"LENGEXAM\",\"LSTBLDS3\",\"LASTSIG3\",\"PSATIME\",\"PCPSARS1\",\n",
    "                           \"EMTSUPRT\",\"LSATISFY\"]\n",
    "preprocessing_refactorisation(variables_for_process16,process_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46ee73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_17(column):\n",
    "    new_column = column.copy()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 8]\n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77) or (new_column[i] == 99) or np.isnan(new_column[i])): # DON'T KNOW / REFUSED \n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ab67b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process17 = [\"LASTSMK2\"]\n",
    "preprocessing_refactorisation(variables_for_process17,process_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92b37b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_18(column):\n",
    "    new_column = column.copy()\n",
    "\n",
    "    filtered_elements = [x for x in new_column if 11 <= x <= 96]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 98) or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4dfe601",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process18 = [\"ASTHMAGE\"]\n",
    "preprocessing_refactorisation(variables_for_process18,process_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec93fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_19(column):\n",
    "    new_column = column\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 98: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 96]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 97)  or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdf4e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process19 = [\"SCNTWRK1\",\"SCNTLWK1\"]\n",
    "preprocessing_refactorisation(variables_for_process19,process_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "976115bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_20(column):\n",
    "    new_column = column\n",
    "    for i in range(len(new_column)):\n",
    "        if new_column[i] == 88: \n",
    "            new_column[i] = 0\n",
    "            \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 14]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 77)  or (new_column[i] == 99) or np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81da80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process20 = [\"ADPLEASR\",\"ADDOWN\",\"ADSLEEP\",\"ADENERGY\",\"ADEAT1\",\"ADFAIL\",\"ADTHINK\",\"ADMOVE\"]\n",
    "preprocessing_refactorisation(variables_for_process20,process_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d12c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_21(column):\n",
    "    new_column = column\n",
    " \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 99999]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ( np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9417d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process21 = [\"GRENDAY_\",\"ORNGDAY_\",\"VEGEDA1_\",\"FTJUDA1_\",\"FRUTDA1_\",\"BEANDAY_\",\"_FRUTSUM\",\"_VEGESUM\",\"PADUR1_\",\"PADUR2_\",\n",
    "                           \"_MINAC11\",\"_MINAC21\",\"PAMIN11_\",\"PAMIN21_\",\"PA1MIN_\",\"PAVIG11_\",\"PAVIG21_\",\"PA1VIGM_\"]\n",
    "preprocessing_refactorisation(variables_for_process21,process_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71d40e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_22(column):\n",
    "    new_column = column\n",
    " \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 128]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ( np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63c24e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process22 = [\"METVL11_\",\"METVL21_\"]\n",
    "preprocessing_refactorisation(variables_for_process22,process_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ca1c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_23(column):\n",
    "    new_column = column\n",
    " \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 98999]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if ((new_column[i] == 99900) or (new_column[i]==99000) or  np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c22f0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process23 = [\"MAXVO2_\",\"FC60_\",\"PAFREQ1_\",\"PAFREQ2_\",\"STRFREQ_\"]\n",
    "preprocessing_refactorisation(variables_for_process23,process_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6b659c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_24(column):\n",
    "    new_column = column\n",
    " \n",
    "    filtered_elements = [x for x in new_column if 0 <= x <= 9999]        \n",
    "    median = np.median(filtered_elements)\n",
    "        \n",
    "    for i in range(len(new_column)):\n",
    "        if (np.isnan(new_column[i])):\n",
    "            new_column[i] = median\n",
    "            \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a28ea4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_for_process24 = [\"_BMI5\"]\n",
    "preprocessing_refactorisation(variables_for_process24,process_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26e6f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO THIS LINE OF CODE MUST BE AT THE END OF THE NOTEBOOK \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "collumns_not_find = {\"DIS\",\"EXACTOT1\",\"QLMENTL2\",\"EXACTOT2\",\"ASINHALRPCPSADE1\",\"PAINACT2\",\"_MICHD\",\"QLSTRES2\",\"QLHLTH2\"}\n",
    "collumns_to_delete = list(set(collumns_to_delete)-collumns_not_find) #remove duplicates\n",
    "\n",
    "\n",
    "indice_to_delete = [feature_names.index(item) for item in collumns_to_delete]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indice_to_delete.sort()\n",
    "\n",
    "x_new_del_train = np.delete(x_new_train,indice_to_delete,1)\n",
    "x_new_del_test = np.delete(x_new_test,indice_to_delete,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0684e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb859cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_del_train = np.hstack((x_new_del_train,x_append_train))\n",
    "x_new_del_test = np.hstack((x_new_del_test,x_append_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3edabc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((328135, 508), (109379, 508))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_del_train.shape,x_new_del_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a59328bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(np.isnan(x_new_del_train)))\n",
    "print(np.count_nonzero(np.isnan(x_new_del_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e56aa3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_parameters(y_test, y_pred):\n",
    "    \"\"\"Calculates the parameters for the metrics\n",
    "    \n",
    "    Args:\n",
    "        y_test: test labels\n",
    "        y_pred: predicted labels\n",
    "        \n",
    "    Returns:\n",
    "        tp: true positive\n",
    "        tn: true negative\n",
    "        fp: false positive\n",
    "        fn: false negative\n",
    "    \"\"\"\n",
    "    #print(y_test.shape, y_pred.shape)\n",
    "    tp = sum((yt == 1) & (yp == 1) for yt, yp in zip(y_test, y_pred))\n",
    "    tn = sum((yt == -1) & (yp == -1) for yt, yp in zip(y_test, y_pred))\n",
    "    fp = sum((yt == -1) & (yp == 1) for yt, yp in zip(y_test, y_pred))\n",
    "    fn = sum((yt == 1) & (yp == -1) for yt, yp in zip(y_test, y_pred))\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def precision(tp, fp):\n",
    "    \"\"\"Calculates the precision score, which is the proportion of positive identifications that are actually correct\n",
    "    \n",
    "    Args: \n",
    "        tp: true positive\n",
    "        fp: false positive\n",
    "        \n",
    "    Returns:\n",
    "        precision score\n",
    "    \n",
    "    \"\"\"\n",
    "    if(tp + fp == 0):\n",
    "        return 0.0\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, fn):\n",
    "    \"\"\"Calculates the recall score, which is the proportion of positives correctly identified. \n",
    "    It is different from precision in that it does not take into account the false positives.\n",
    "    \n",
    "    Args:\n",
    "        tp: true positive\n",
    "        fn: false negative\n",
    "        \n",
    "    Returns:\n",
    "        recall score\n",
    "    \"\"\"\n",
    "    if(tp + fn == 0):\n",
    "        return 0.0\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(tp, fp, fn):\n",
    "    \"\"\"Calculates the f1 score, which is the harmonic mean of precision and recall\n",
    "    \n",
    "    Args:\n",
    "        tp: true positive\n",
    "        fp: false positive\n",
    "        fn: false negative\n",
    "        \n",
    "    Returns:\n",
    "        f1 score\n",
    "    \"\"\"\n",
    "    denom = precision(tp, fp) + recall(tp, fn)\n",
    "    if(denom == 0):\n",
    "        return 0.0\n",
    "    return 2 * precision(tp, fp) * recall(tp, fn) / denom\n",
    "\n",
    "def accuracy(tp, tn, fp, fn):\n",
    "    \"\"\"Calculates the accuracy score, which is the proportion of correct predictions\n",
    "    \n",
    "    Args:\n",
    "        tp: true positive\n",
    "        tn: true negative\n",
    "        fp: false positive\n",
    "        fn: false negative\n",
    "        \n",
    "    Returns:\n",
    "        accuracy score\n",
    "    \"\"\"\n",
    "    denom = (tp + tn + fp + fn)\n",
    "    if(denom == 0):\n",
    "        return 0.0\n",
    "    return (tp + tn) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a918e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import implementations\n",
    "import random\n",
    "\n",
    "def cross_validation_log(x, y, k_folds, hyperparameters):\n",
    "\n",
    "    # Lists to store performance metrics for each fold and lambda\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    # Split the data into k_fold parts\n",
    "    fold_size = len(x) // k_folds\n",
    "    \n",
    "    # Dictionary to store results for each set of hyperparameters\n",
    "    results = {}\n",
    "    \n",
    "    for lambda_ in hyperparameters:\n",
    "\n",
    "        for k in range(k_folds):\n",
    "            # Split the data into training and validation sets\n",
    "            start = k * fold_size\n",
    "            end = (k + 1) * fold_size\n",
    "            x_valid = x[start:end]\n",
    "            y_valid = y[start:end]\n",
    "            x_train_fold = np.concatenate((x[:start], x[end:]))\n",
    "            y_train_fold = np.concatenate((y[:start], y[end:]))\n",
    "            \n",
    "            # Train the model using logistic or regularized logistic regression\n",
    "            w, loss = implementations.ridge_regression(\n",
    "                y_train_fold, \n",
    "                x_train_fold, \n",
    "                lambda_, \n",
    "            )\n",
    "               \n",
    "            y_pred = x_valid.dot(w)\n",
    "            y_pred=(y_pred>0)*2-1\n",
    "\n",
    "            #print(\"y_pred is:\" ,    y_pred)\n",
    "            # # Make predictions on the validation set\n",
    "            # y_pred = np.sign(x_valid.dot(w)) # this function returns -1 or 1\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            tp, tn, fp, fn = calculate_parameters(y_valid, y_pred)\n",
    "            f1_scores.append(f1_score(tp, fp, fn))\n",
    "            accuracy_scores.append(accuracy(tp, tn, fp, fn))\n",
    "            \n",
    "        # Calculate the mean performance metrics for each set of hyperparameters\n",
    "        mean_f1 = np.mean(f1_scores)\n",
    "        mean_accuracy = np.mean(accuracy_scores)\n",
    "        \n",
    "        # Store the results in the dictionary\n",
    "        results[str(lambda_)] = {'F1 score': mean_f1, 'Accuracy': mean_accuracy, 'param w ':w}\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_random_hyperparameters(num_samples):\n",
    "    \"\"\"Generates a list of random hyperparameters\n",
    "    \n",
    "    Args:\n",
    "        num_samples: number of sets of hyperparameters to generate\n",
    "        num_features: number of features in the dataset\n",
    "        \n",
    "    Returns:\n",
    "        hyperparameters_list: list of hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return np.linspace(1e-16, 0.001, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524032d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe1cbfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508, 1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "num_sample = 5\n",
    "\n",
    "num_features = x_new_del_train.shape[1]\n",
    "\n",
    "random_hyperparameters = generate_random_hyperparameters(num_samples)\n",
    "\n",
    "\n",
    "k_folds = 5\n",
    "\n",
    "results = cross_validation_log(x_new_del_train, y_train, k_folds, random_hyperparameters)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cf895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13831037207587873\n",
      "1e-16\n",
      "0.13826124495595637\n",
      "2.500000075e-09\n",
      "0.1382448692493156\n",
      "5.00000005e-09\n",
      "0.13823668139599518\n",
      "7.500000025e-09\n",
      "0.13823176868400297\n",
      "1e-08\n"
     ]
    }
   ],
   "source": [
    "for a in results:\n",
    "    print(results[a][\"F1 score\"])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model found so far : \n",
    "\n",
    "# ridge_regression with lambda = 1e-16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import implementations\n",
    "import importlib\n",
    "importlib.reload(implementations)\n",
    "from implementations import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "initial_w = np.zeros(x_new_del_train.shape[1]) \n",
    "\n",
    "## Todo better initialization ? maybe normal distributed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MaxIter = 100000\n",
    "gamma = 0.01\n",
    "\n",
    "w,loss = ridge_regression(y_train, x_new_del_train,0.01) ## GAVE 0.063 F1 SCORE , maybe use lambda really small to approximate a least square \n",
    "\n",
    "#w,loss = implementations.logistic_regression(y_train, x_new_del_train, initial_w, MaxIter, gamma)\n",
    "\n",
    "\n",
    "w.shape,x_new_del_test.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred4 = x_new_del_test.dot(w)\n",
    "y_pred4=(y_pred4>0)*2-1\n",
    "y_pred4\n",
    "\n",
    "helpers.create_csv_submission(test_ids, y_pred4, \"Submission4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression().fit(x_new_del_train,y_train)\n",
    "y_pred3 = clf.predict(x_new_del_test)\n",
    "y_pred3 = (y_pred3>0)*2-1\n",
    "helpers.create_csv_submission(test_ids, y_pred3, \"Submission3.csv\") # gave 0.132 F1 score , Problem , we're not allowed to use it for the final submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
